\input{meta/pldi23-preamble}

\let\Bbbk\relax
\usepackage{amssymb}
\usepackage[checkNoComments]{hydrocomments}
\usepackage{utf8math,ttquot,mathpartir,amsmath, mathtools,multicol,xspace,stmaryrd }


\begin{document}

\title{HydroFlow: A New Dataflow Programming Language}

\input{meta/authors}
\input{meta/ccs-and-keywords.tex}

%%
%% The abstract is a short summary of tThe work to be presented in the
%% article.
\begin{abstract}

%In this paper we introduce the HydroFlow programming language, a new 

\end{abstract}

\maketitle

\section{Introduction}

\MPM{This is intentionally badly-written. Think of it like an outline that was formatted like a paper.}

Dataflow programming remains a compelling abstraction for cloud-based distributed computation.  In a dataflow program, a series of computational units known as _operators_ are arranged in a graph, with output from one operator ``flowing'' to its successor.  Each operator then processes a stream of inputs, and produces a stream of outputs directed at its next operator in sequence. This model of computation first gained popularity in the distributed systems community via projects like Dryad \cite{dryad} and MapReduce \cite{mapreduce}, but finds its origins within the databases community, primarily as a way of representing and executing SQL queries \cite{sql-dataflow}. Modern incarnations of distributed dataflow programming models, such as Materialize's Differential Dataflow and Apache's Spark and Storm \cite{spark, storm}, suffer from three major limitations: (1) Run-time type failures, (2) frequent barriers or retractions, (3) poor scalability.\MPM{Obviously we need to say more about these here, and not just wait until the background section.} 

In this work we present the HydroFlow programming language, a new dataflow language and runtime designed to overcome these three limitations. I should say a sentence here about the basics of HydroFlow, like users write Operators in a traditional systems programming language, and combine operators into stream-processing programs via a simple graph description syntax. First, HydroFlow's strong static type system is capable of encoding not just the types of data elements that flow through streams, but also _properties_ of the streams themselves: for example, the type of items in a hydroflow stream might statically indicate that stream elements are comparable, while the _stream properties_ may ensure that these elements arrive in _monotonically ascending_ order.  This strong type system can statically detect many more type errors, preventing run-time crashes. Second, HydroFlow can leverage its stream properties to perform a _monotonicity analysis_, indicating whether a given operator is safe to run _incrementally_, and thereby solving the latency issues encountered by the introduction of barriers in traditional stream processing systems, or the consistency issues which arise from the unwise elision thereof. Finally, HydroFlow addresses dataflow scalability concerns by introducing rewriting-based optimizations familiar to the world of SQL directly into the dataflow language itself. In HydroFlow, users may provide new operators along with an _axiomatic specification_ of their behavior; the HydroFlow compiler than uses an SMT-based analysis to determine potential rewrite axioms that relate all operators, allowing a traditional SQL-style optimization approach to full HydroFlow programs---even in the presence of arbitrary user-provided code.

Hydroflow is implemented as a deep embedding into the Rust programming language \cite{rust}.  Our compilation stack ensures all operators are compiled alongside their assembled graph, allowing the Rust compiler to perform aggressive inlining and copy-elision, erasing the overhead of  operator handoffs and greatly improving on the performance of similar tools such as timely dataflow \cite{timely-dataflow}.  In particular, our tool demonstrates some quantifiable improvement in some benchmark or other that will prove quite compelling here.

The rest of the paper proceeds as follows.  Section \ref{sec:background}
 provides background on the challenges faced by existing distributed dataflow environments. Section \ref{sec:hydroflow-overview} provides an overview of the hydroflow programming language, with examples of both hydroflow programs and implementing operators. Section \ref{sec:hydroflow-semantics} describes the formal semantics of hydroflow, with a focus on the semantics of stream properties. Section \ref{sec:hydroflow-types} describes the HydroFlow type system, Section \ref{sec:hydroflow-implementation} describes the implementation, and \ref{sec:experimental-results} reviews its performance on several benchmarks.  We also have a related work and conclusion somewhere. 

\section{Background: The three major problems of existing streaming frameworks}
\label{sec:background}

It could perhaps make sense to put a more step-by-step overview of distributed streaming systems here, rather than rely on a drive-by explanation in the intro. Especially considering our audience is PL, who have certainly _heard_ of these things but have no real idea how the work or why they are used. 

\subsection{Stream Property Violations}

While the use of static types to eliminate the most common classes of errors is common in some distributed dataflow frameworks, these static types reflect only the power of the underlying type system. While they are able to reason about the type of the individual elements flowing through each stream, they are unable to reason about properties of the _stream itself_, which may be assumed to hold by downstream operators. Thus, each operators must independently enforce any stream properties at run-time, choosing to expose the programmer to crashes---or worse, logic errors.

\subsection{Barriers, Retractions, and State: oh my!}

When streaming computations are paired with state (as is their common case), thorny issues of consistency and determinism can quickly arise.  Consider, for example, an operator that runs a single query φ on the entire stream, producing a single boolean result ($φ : stream → bool$). Implementing such operators is challenging; existing systems generally take one of three approaches.  Industry-standard dataflow environments (like Spark and such) take the conservative approach; they wait for a distinguished end-of-stream message\MPM{say something intelligent about batching here or something}, after which they are able to safely run φ on the entire stream.  Other systems, most notably differential dataflow, take a different approach; they will continuously re-evaluate φ on each input, issuing a _retraction_ if the result of φ should ever change.  It is then the responsibility of downstream operators to determine how to use this retraction to adjust their own computational results.  Within the PL space, reactive programming frameworks have solved this problem in a number of ways; most commonly, upon the arrival of an updated value, a reactive pipeline will be re-run up until a previously-computed intermediate result is encountered.

All of these solutions have significant drawbacks.  In distributed dataflow, a batching approach significantly complicates the problem of distributed scheduling; downstream operators must sit idle while whole-stream queries wait for their inputs to finish arriving, and so great effort must be spent to ensure that any nodes which power downstream operators are put to good use in the interim. Regardless of whether the scheduling problem can be solved satisfactorily, there is the issue of latency; blocking until the end of input threatens liveness, and can delay computation results indefinitely. 

Meanwhile, both retractions and re-executions feature significant wasted computation.  In the best case, retractions must effectively produce _new_ computation to undo the effects of old, resulting in many CPU-hours wasted; in the worst case, retractions arrive too late, opening the application up to consistency issues.  Re-executions, meanwhile, are unable to determine ahead of time if the re-execution will meaningfully alter the value computed by the reactive program, stopping only if a cached intermediate result has been dynamically detected.\MPM{I feel like I need to read more FRP to make sure this is actually true, and I shouldn't be re-pitching this as "bringing an FRP insight to dataflow" or something.}  This can lead to significant wasted re-computation; for example, when computing if the cardinality of a set is above a certain threshold, these computations would continuously re-compute the set cardinality, only to determine that it has no effect on the threshold and thus no effect on the overall computation. 

\subsection{Scaling manually, if at all}

Distributed frameworks are often lauded for their scalability; indeed, the ability to schedule various operators across and entire clusters of nodes, rather than have fixed roles for each machine, produces a degree of dynamic flexibility and allows architectures to scale the resources provided to each individual operator.  But these scaling approaches can only go so far; they rely on finding different execution strategies for the same graph, but ignore opportunities for optimization which require rewriting the graph itself. 

SQL optimizers, meanwhile, have long relied on the ability to rewrite dataflow graphs. A SQL query engine generates a dataflow graph from a SQL query, and can reason equationally about SQL queries in order to discover a distinct dataflow program which is capable of more efficiently computing the desired result. While this often produces a strictly-more-optimal query, SQL engines (unlike traditional compiler optimizations) have the benefit of knowing something about the data on which the program will be running; they can thus make optimization decisions which are tailored to the expected data, and thus can achieve far greater efficiency. 

Bringing these benefits to the general domain of distributed dataflow programming poses a challenge: SQL optimizers assume complete knowledge of program text, and allow only a small set of operators.  Crucially, there are no abstractions in these programs beyond tables and no extensibility or modularity beyond ``user-defined functions (UDFs),'' which must be treated conservatively by the optimizer and which allow only a restrictive class of additional computations.  In contrast, the world of distributed dataflow programming frequently features custom operators, and increasingly relies on abstractions in the form of both libraries and modular program design \cite{hope-this-is-true!}. Thus, modern dataflow libraries largely make no attempt to perform rewriting optimizations; those which do perform rewriting optimizations simply defer to SQL as an input language, allowing traditional query optimization assumptions to hold. 

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}
\bibliography{thesis,pm-master}

\end{document}
\endinput
%%
%% End of file `sample-acmsmall-conf.tex'.
